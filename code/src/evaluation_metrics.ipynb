{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.py Loading\n",
      "Reading HDI dataset\n",
      "co2prod: min=0.0, max=33.3863\n",
      "hdi: min=0.257, max=0.967\n",
      "le: min=37.105, max=85.473\n",
      "gdi: min=0.383, max=1.041\n",
      "eys: min=3.5751, max=23.2477\n",
      "mys: min=1.4606, max=14.2559\n",
      "\n",
      "Data scaled\n",
      "co2prod: min=0.0, max=1.0\n",
      "hdi: min=0.0, max=1.0\n",
      "le: min=0.0, max=1.0\n",
      "gdi: min=0.0, max=1.0\n",
      "eys: min=0.0, max=1.0\n",
      "mys: min=0.0, max=1.0\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from utils.utils import *\n",
    "import utils.promethee_functions as pf\n",
    "import utils.clustering_functions as cf\n",
    "\n",
    "data = read_data()\n",
    "# Nb of criteria\n",
    "K = data.columns.shape[0] # Nb of criteria\n",
    "L = data.iloc[0][\"co2prod\"].shape[0] # Length of the time series\n",
    "\n",
    "\n",
    "group0 = [\"PAK\", \"SDN\", \"BDI\", \"HTI\"]\n",
    "group1 = [\"EST\", \"CZE\", \"MLT\", \"SGP\", \"IRL\"]\n",
    "group2 = [\"CHE\", \"ISL\", \"NZL\", \"SWE\"]\n",
    "\n",
    "all_groups = group0 + group1 + group2\n",
    "\n",
    "data = data.loc[all_groups]\n",
    "\n",
    "data = scale_data(data)\n",
    "\n",
    "print(\"\\nData scaled\")\n",
    "get_min_max_criteria(data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PAK', 'SDN', 'BDI', 'HTI'],\n",
       " ['EST', 'CZE', 'MLT', 'SGP', 'IRL'],\n",
       " ['CHE', 'ISL', 'NZL', 'SWE']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = [group0, group1, group2]\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso3\n",
       "PAK    [0.9758013116603509, 0.976721908513296, 0.9757...\n",
       "SDN    [0.9911965293383521, 0.9919595069996899, 0.993...\n",
       "BDI    [0.9992023677291763, 0.9990114927479534, 0.999...\n",
       "HTI    [0.9947065203015965, 0.9949419973396827, 0.995...\n",
       "EST    [0.0, 0.0721707642540932, 0.32579554710505815,...\n",
       "CZE    [0.32192410394855164, 0.38557088790790495, 0.3...\n",
       "MLT    [0.7179655598003531, 0.7384510061757973, 0.738...\n",
       "SGP    [0.3874761727105134, 0.3972690098937967, 0.375...\n",
       "IRL    [0.5983674281281074, 0.5917314934679975, 0.596...\n",
       "CHE    [0.7206720525440102, 0.7117422603965367, 0.715...\n",
       "ISL    [0.6297037413466369, 0.6536514155842347, 0.634...\n",
       "NZL    [0.6812110990476761, 0.680625580248843, 0.6613...\n",
       "SWE    [0.7143769854590014, 0.7147643462845307, 0.717...\n",
       "Name: co2prod, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2prod = data[\"co2prod\"]\n",
    "co2prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = []\n",
    "# Define the centroids of the clusters\n",
    "for cluster in clusters:\n",
    "    centroid = np.zeros_like(co2prod.iloc[0])\n",
    "    for country in cluster:\n",
    "        centroid += co2prod.loc[country]\n",
    "    centroid /= len(cluster)\n",
    "    centroids.append(centroid)\n",
    "\n",
    "centroids = np.array(centroids)\n",
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(2.4344475392631133),\n",
       " np.float64(1.712223600243771),\n",
       " np.float64(0.7605762037892209)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the distances between clusters\n",
    "inter_cluster_distances = []\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(i+1, len(clusters)):\n",
    "        inter_cluster_distances.append(np.linalg.norm(centroids[i] - centroids[j]))\n",
    "\n",
    "inter_cluster_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.17868947685737727),\n",
       " np.float64(1.9341718961490786),\n",
       " np.float64(1.1755711350624918)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the diameter of each cluster\n",
    "# Diameter = max distance between two countries in the cluster\n",
    "cluster_diameters = []\n",
    "for cluster in clusters:\n",
    "    diameter = 0\n",
    "    for i in range(len(cluster)):\n",
    "        for j in range(i+1, len(cluster)):\n",
    "            diameter = max(diameter, np.linalg.norm(co2prod.loc[cluster[i]] - co2prod.loc[cluster[j]]))\n",
    "    cluster_diameters.append(diameter)\n",
    "\n",
    "cluster_diameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3932309249780344)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunn_index = min(inter_cluster_distances) / max(cluster_diameters)\n",
    "dunn_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'co2prod': np.float64(0.3932309249780344),\n",
       " 'hdi': np.float64(0.39579279031086606),\n",
       " 'le': np.float64(0.26273938806215114),\n",
       " 'gdi': np.float64(0.05137623166662448),\n",
       " 'eys': np.float64(0.3902749917533445),\n",
       " 'mys': np.float64(0.4789228091604594)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dunn_index_multivariate(clusters, data):\n",
    "    \"\"\" \n",
    "        Compute the Dunn index for a clustering of multivariate time series data\n",
    "        - clusters: list of lists of indexes of the time series in each cluster\n",
    "        - data: the data set (dataframe with index as id of the time series), each cell is a np.array (time series)\n",
    "    \"\"\"\n",
    "    def dunn_index_univariate(clusters, data):\n",
    "        \"\"\"\n",
    "            Compute the Dunn index for a clustering of univariate time series data\n",
    "            - clusters: list of lists of indexes of the time series in each cluster\n",
    "            - data: the data set (dataframe with index as id of the time series), only one column where each cell is a np.array (time series)\n",
    "        \"\"\"\n",
    "        centroids = []\n",
    "\n",
    "        # Define the centroids of the clusters\n",
    "        for cluster in clusters:\n",
    "            centroid = np.zeros_like(data.iloc[0])\n",
    "            for country in cluster:\n",
    "                centroid += data.loc[country]\n",
    "            centroid /= len(cluster)\n",
    "            centroids.append(centroid)\n",
    "\n",
    "        centroids = np.array(centroids)\n",
    "        \n",
    "        # Compute the distances between clusters\n",
    "        inter_cluster_distances = []\n",
    "        for i in range(len(clusters)):\n",
    "            for j in range(i+1, len(clusters)):\n",
    "                inter_cluster_distances.append(np.linalg.norm(centroids[i] - centroids[j]))\n",
    "\n",
    "        # Compute the diameter of each cluster\n",
    "        # Diameter = max distance between two countries in the cluster\n",
    "        cluster_diameters = []\n",
    "        for cluster in clusters:\n",
    "            diameter = 0\n",
    "            for i in range(len(cluster)):\n",
    "                for j in range(i+1, len(cluster)):\n",
    "                    diameter = max(diameter, np.linalg.norm(data.loc[cluster[i]] - data.loc[cluster[j]]))\n",
    "            cluster_diameters.append(diameter)\n",
    "\n",
    "        dunn_index = min(inter_cluster_distances) / max(cluster_diameters)\n",
    "        return dunn_index\n",
    "\n",
    "    indexes = {}\n",
    "    criterias = data.columns\n",
    "\n",
    "    for criteria in criterias:\n",
    "        indexes[criteria] = dunn_index_univariate(clusters, data[criteria])\n",
    "    \n",
    "    return indexes\n",
    "\n",
    "dunn_index_multivariate(clusters, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
